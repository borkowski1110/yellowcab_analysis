{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import hiplot as hip   \n",
    "from scipy.stats import ttest_ind\n",
    "import os \n",
    "\n",
    "os.chdir('src')\n",
    "from toolkit.etl_toolkit import ingest_data\n",
    "from toolkit.analysis_toolkit import inspect_distribution, calculate_drivetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-bb9307b6dbe4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#2.8 GB of RAM consumed -- it could be impossible to load the full dataset at once. Using dask for modelling should be considered\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mstatic_draft\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mingest_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'2018'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'01'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;31m#Creating the graph for sister dataset. It will be used for future comparisons\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0msister_draft\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mingest_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'2019'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'01'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#From now on the data (resp. column) drawn from a next year I will refer to as ,,sister data\" (resp. ,,sister column\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3.7\\lib\\site-packages\\dask\\base.py\u001b[0m in \u001b[0;36mcompute\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    164\u001b[0m         \u001b[0mdask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m         \"\"\"\n\u001b[1;32m--> 166\u001b[1;33m         \u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraverse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    167\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3.7\\lib\\site-packages\\dask\\base.py\u001b[0m in \u001b[0;36mcompute\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    435\u001b[0m     \u001b[0mkeys\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__dask_keys__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcollections\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    436\u001b[0m     \u001b[0mpostcomputes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__dask_postcompute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcollections\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 437\u001b[1;33m     \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mschedule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdsk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    438\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mrepack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpostcomputes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    439\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3.7\\lib\\site-packages\\dask\\threaded.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(dsk, result, cache, num_workers, pool, **kwargs)\u001b[0m\n\u001b[0;32m     82\u001b[0m         \u001b[0mget_id\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_thread_get_id\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m         \u001b[0mpack_exception\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpack_exception\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 84\u001b[1;33m         \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     85\u001b[0m     )\n\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3.7\\lib\\site-packages\\dask\\local.py\u001b[0m in \u001b[0;36mget_async\u001b[1;34m(apply_async, num_workers, dsk, result, cache, get_id, rerun_exceptions_locally, pack_exception, raise_exception, callbacks, dumps, loads, **kwargs)\u001b[0m\n\u001b[0;32m    473\u001b[0m             \u001b[1;31m# Main loop, wait on tasks to finish, insert new ones\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    474\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"waiting\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"ready\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"running\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 475\u001b[1;33m                 \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mres_info\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfailed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mqueue_get\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mqueue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    476\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mfailed\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    477\u001b[0m                     \u001b[0mexc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres_info\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3.7\\lib\\site-packages\\dask\\local.py\u001b[0m in \u001b[0;36mqueue_get\u001b[1;34m(q)\u001b[0m\n\u001b[0;32m    123\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    124\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 125\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    126\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3.7\\lib\\queue.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    177\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mremaining\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m                         \u001b[1;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 179\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    180\u001b[0m             \u001b[0mitem\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnot_full\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnotify\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3.7\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    298\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    299\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 300\u001b[1;33m                     \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    301\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    302\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#2.8 GB of RAM consumed -- it could be impossible to load the full dataset at once. Using dask for modelling should be considered\n",
    "static_draft = ingest_data('2018', '01').compute()\n",
    "#Creating the graph for sister dataset. It will be used for future comparisons\n",
    "sister_draft = ingest_data('2019', '01')\n",
    "#From now on the data (resp. column) drawn from a next year I will refer to as ,,sister data\" (resp. ,,sister column\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(static_draft.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "static_draft.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is less than ten times less ,,unique\" records (based on index). That is odd, it is impossible for the index to represent the specific driver (there would be less than twenty drivers in NYC city then). We will inspect that matter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "static_draft.loc[1, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no clear similarity in these rows, except an improvement surcharge which is said to take only values from {0, 0.5}, so cannot be related to an index. Nonethless from now on I will be reffering to records with the same index as unique trips."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Pre-inspecting the data based on January rides.\n",
    "### 1.1 Domain understanding: Inspecting the variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "static_draft.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "static_draft.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reference for choosing wether the data is stored in the suitable format. \n",
    "#With EDA results it will be used for a proper pipeline design.\n",
    "static_draft.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.1 Column insights: VendorID\n",
    "Indicates the **TPEP** (Taxicab Passenger Enhancement Program) provider of a record. \n",
    "Unique values:\n",
    "    \n",
    "   1) 1 := Creative Mobile Technologies, LLC; \n",
    "    \n",
    "   2) 2 := VeriFone Inc.\n",
    "    \n",
    "Treated as categorical variable. I will now proceed with inspecting its relevancy i.e. the impact that it makes on distribution of the rest of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "static_draft['VendorID'].value_counts()/len(static_draft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For locations\n",
    "hip.Experiment.from_dataframe(static_draft.iloc[:100, :].loc[:, ['VendorID', 'PULocationID', 'DOLocationID']]).display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that there are no separate districts in which the both providers operate. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.2 Column insights: tpep_pickup_datetime, tpep_dropoff_datetime\n",
    "The date and time when the meter was engaged/disengaged.\n",
    "\n",
    "Format of the string: 'yyyy-mm-dd hh:mm:ss'\n",
    "Will be used to create an indicator wether it was a night ride as well as for calculating how long it lasted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "static_draft.loc[:, 'drivetime'] = calculate_drivetime(static_draft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inspect_distribution(static_draft.head(500000)['drivetime'], True, calculate_drivetime(sister_draft.head(500000)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data seems to be concentrated on a shorter rides (time given in minutes), which is of high importance taking under consideration initial fee's, more quick drives means shorter distances, less time spent on returning to the city centre and more engaging fees collected. Nonetheless the outliers should be inspected. But first the equal expected values hypothesis will be tested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#T test results.\n",
    "ttest_ind(static_draft.head(500000)['drivetime'], calculate_drivetime(sister_draft.head(500000)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It will be assumed that the year-to-year expected drivetime is changing - decreasing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "static_draft.loc[static_draft['drivetime'] > 100, :].sort_values('fare_amount')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that the outliers may be related both to the personal errands or even trips (negative fare) and longer drives. The odd thing is that some of the heavily charged services are not related to driving the passengers at all. That is why I would recomend not using these records in EDA and modelling processes as they need more care.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inspect_distribution(static_draft.loc[static_draft['drivetime'] < 100, :].head(1000)['drivetime'], True, [x if x < 100 else None for x in calculate_drivetime(sister_draft.head(1000))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Managing the outlying trips, based on the drivetime\n",
    "static_draft = static_draft.loc[static_draft['drivetime'] < 100, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#6.6. GB consumed\n",
    "sister_draft = sister_draft.compute()\n",
    "sister_draft = sister_draft.loc[calculate_drivetime(sister_draft) < 100, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.3 Column insights: passenger_count\n",
    "The number of passengers, driver included. Should be checked for any anomalies, maybe the relation to the length of the ride and drivespeed should be inspected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inspect_distribution(static_draft['passenger_count'][1000:20000], True, sister_draft['passenger_count'][1000:20000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There seems to be some personal or anomaly trips included in the data. Let's inspect them before dropping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "static_draft.loc[static_draft['passenger_count'] == 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "static_draft.loc[static_draft['passenger_count'] == 0, ['VendorID', 'payment_type']].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(static_draft['VendorID'], static_draft['passenger_count'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Occurences of the 'zero-passengers' records are related to the VendorID, maybe there were some difficulties in collecting this data? These records will be excluded from modelling but included in the further EDA for the rest of related variables seems intact. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.4 Column insights: store_and_fwd_flag\n",
    "\n",
    "This flag indicates whether the trip record was held in vehicle memory before sending to the vendor, because the vehicle did not have a connection to the server. \n",
    "Unique values:\n",
    "1. Y= store and forward trip\n",
    "\n",
    "2. N= not a store and forward trip\n",
    "\n",
    "This column will not be used in further analysis for its highly probable irrelevance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "static_draft = static_draft.drop('store_and_fwd_flag', 1)\n",
    "sister_draft = sister_draft.drop('store_and_fwd_flag', 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.5 Column insights: payment_type\n",
    "A numeric code signifying how the passenger paid for the trip.\n",
    "Unique values: \n",
    "\n",
    "1. 1= Credit card\n",
    "\n",
    "2. 2= Cash\n",
    "\n",
    "3. 3= No charge\n",
    "\n",
    "4. 4= Dispute\n",
    "\n",
    "5. 5= Unknown\n",
    "\n",
    "6. 6= Voided trip\n",
    "\n",
    "If I were to express my opinion I would call this column the one of the most important one. That is because that grim ''dispute\" value. Intuitively it could be related to default in payment, in any case this matter demands an inquiry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inspect_distribution(static_draft['payment_type'][2000:30000], True, sister_draft['payment_type'][2000:30000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "static_draft['payment_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inspect_distribution(static_draft.loc[static_draft['payment_type'] == 4, 'fare_amount'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like the 'dispute' value not necessarily indicates that the whole charge was lost, but we encounter some negative values. Now the average fare and assumed loss on these trips will be calculated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "static_draft.loc[static_draft['fare_amount'] < 0, ['fare_amount', 'payment_type']].groupby('payment_type').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.6 Column insights: ratecodeID\n",
    "\n",
    "RatecodeID\n",
    "The final rate code in effect at the end of the trip.\n",
    "\n",
    "Unique values:\n",
    "\n",
    "1= Standard rate\n",
    "\n",
    "2=JFK\n",
    "\n",
    "3=Newark\n",
    "\n",
    "4=Nassau or Westchester\n",
    "\n",
    "5=Negotiated fare\n",
    "\n",
    "6=Group ride\n",
    "\n",
    "It is worth checking if predicting the negotiated fare would have any business value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "static_draft['RatecodeID'].value_counts()/len(static_draft)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are only a few negotiated fares and category '99' which origins are rather blurry, the column will be dropped before EDA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.7 Column insights: financial data\n",
    "\n",
    "1. fare_amount\n",
    "The time-and-distance fare calculated by the meter.\n",
    "\n",
    "2. extra\n",
    "Miscellaneous extras and surcharges. Currently, this only includes the 0.50 dollar and 1 dollar rush hour and overnight charges.\n",
    "\n",
    "3. mta_tax\n",
    "0.50 dollar MTA tax that is automatically triggered based on the metered rate in use.\n",
    "\n",
    "4. improvement_surcharge\n",
    "0.30 dollar improvement surcharge assessed trips at the flag drop.\n",
    "\n",
    "5. tip_amount\n",
    "Tip amount – This field is automatically populated for credit card tips. Cash tips are not included.\n",
    "\n",
    "6. tolls_amount\n",
    "Total amount of all tolls paid in trip.\n",
    "\n",
    "7. total_amount\n",
    "The total amount charged to passengers. Does not include cash tips.\n",
    "\n",
    "I will use this data to check wether the \"dispute\" payment type really has any impact on the final charge. Also the presence of the tip amount-related information could indicate that there was a card payment, which could be used to fill some of the missing payment type data. \n",
    "\n",
    "In the next notebooks I am planning to use just \"fare_amount\", \"tip_amount\" and \"extra\" variables for their relevance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(static_draft.loc[static_draft['fare_amount'] < 0, :])/len(static_draft)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Negative charge records are sparse and for their sparsity the will not be included in further analysis. Their relation to pickup and dropoff location also seems unclear."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.8 Column insights: PULocationID, DOLocationID\n",
    "\n",
    "Respectively: TLC Taxi Zone in which the taximeter was engaged, TLC Taxi Zone in which the taximeter was disengaged.\n",
    "\n",
    "These will be used for modellig trip duration/speed/total charge. There is lookup table provided by TLC, it could be used to decypher the Borough, Zone and the information which type of taxi services the specific zone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zone_lookup = pd.read_csv('https://s3.amazonaws.com/nyc-tlc/misc/taxi+_zone_lookup.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zone_lookup.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hip.Experiment.from_dataframe(static_draft.iloc[:10000, :].loc[:, ['total_amount', 'PULocationID', 'DOLocationID']]).display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obviously there is correlation between pickup/dropoff location and the total amount charged but could it be simplified by using the Boroughs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "zone_dictionary = pd.Series(zone_lookup.Borough.values,index=zone_lookup.LocationID).to_dict()\n",
    "sample_draft = static_draft.head(10000).loc[:, ['total_amount', 'PULocationID', 'DOLocationID']]\n",
    "\n",
    "sample_draft = sample_draft.replace({\"PULocationID\":zone_dictionary}).replace({\"DOLocationID\":zone_dictionary})\n",
    "\n",
    "hip.Experiment.from_dataframe(sample_draft.iloc[:100, :].loc[:, ['total_amount', 'PULocationID', 'DOLocationID']]).display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be easily spotted that both least and most expensive trips routes lies entirely in Manhattan. It is striking that some of the Boroughs are just disproportionately large. For a more in depth analysis it would be an asset to collect the data regarding boroughs size and population. In the next notebook I am going to engineer the feature \"borough\" size by simply counting the IDs for every Borough in the zone lookup table.\n",
    "\n",
    "The pickups from zone other than yellow taxi zone will not be taken into account as formally drivers cannot take passengers from other taxi zone. Because of that I expect some fare anomalies in these cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre- EDA Summary \n",
    "\n",
    "#### Matters that needs to be tended in the preprocessing:\n",
    "\n",
    "1. Dropping unused columns\n",
    "\n",
    "2. Cleaning missing values if any encountered \n",
    "\n",
    "3. Converting timestamp columns to the proper type and format \n",
    "\n",
    "4. Cleaning negative trip durations, trip distances, \n",
    "\n",
    "5. Cleaning negative fares\n",
    "\n",
    "6. Cleaning the trips with no passengers\n",
    "\n",
    "7. Encoding the variables that should be categorical\n",
    "\n",
    "#### Feature engineering:\n",
    "\n",
    "1. Calculate Borough sizes using number of zones that every one of them contains\n",
    "\n",
    "2. Calculate average drive speed\n",
    "\n",
    "3. Calculate the drivetime.\n",
    "\n",
    "4. Create the indicator wether it was a night/rush hour course.\n",
    "\n",
    "5. Create the indicator showing if the trip happened during the weekend\n",
    "\n",
    "6. Create a season indicator (for models trained on many months).\n",
    "\n",
    "7. Optionally merge the outlying payment types together into the \"uncommon\" category.\n",
    "\n",
    "#### Features to keep from the original dataset:\n",
    "\n",
    "1. PULocationID and DOLocationID\n",
    "2. tpep_pickup_datetime and tpep_dropoff_datetime\n",
    "3. passenger_count\n",
    "4. trip_distance\n",
    "5. payment_type\n",
    "6. fare_amount\n",
    "7. extra\n",
    "8. tip_amount\n",
    "\n",
    "### Handling anomalies\n",
    "\n",
    "Erase rows where: \n",
    "\n",
    "1. PULocationID or DOLocationID is in {0, 264, 265}\n",
    "\n",
    "2. Total amount is negative\n",
    "\n",
    "3. \"extra\" value is negative \n",
    "\n",
    "4. \"tip_amount\" is negative\n",
    "\n",
    "5. Trip lasts longer than 100 minutes or its duration is less than 0 minutes.\n",
    "\n",
    "6. Erase rows with missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Useful links. \n",
    "Dictionary: https://www1.nyc.gov/assets/tlc/downloads/pdf/data_dictionary_trip_records_yellow.pdf\n",
    "\n",
    "Lookup table regarding IDs: https://s3.amazonaws.com/nyc-tlc/misc/taxi+_zone_lookup.csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
